# Comparing `tmp/viqi_api-0.6.4.0-py3-none-any.whl.zip` & `tmp/viqi_api-0.6.4.1-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,35 +1,23 @@
-Zip file size: 80303 bytes, number of entries: 33
--rw-rw-rw-  2.0 unx      417 b- defN 23-Apr-05 15:43 vqapi/README.md
--rw-r--r--  2.0 unx      272 b- defN 23-Apr-05 15:43 vqapi/__init__.py
--rw-r--r--  2.0 unx     1743 b- defN 23-Apr-05 15:43 vqapi/blockable_module.py
--rw-r--r--  2.0 unx    28849 b- defN 23-Apr-05 15:43 vqapi/bqclass.py
--rw-rw-rw-  2.0 unx    16175 b- defN 23-Apr-05 15:43 vqapi/bqfeature.py.old
--rw-rw-rw-  2.0 unx    24743 b- defN 23-Apr-05 15:43 vqapi/bqnode.py.save
--rw-r--r--  2.0 unx     1594 b- defN 23-Apr-05 15:43 vqapi/casauth.py
--rw-r--r--  2.0 unx     6312 b- defN 23-Apr-05 15:43 vqapi/cmd.py
--rw-r--r--  2.0 unx    50428 b- defN 23-Apr-05 15:43 vqapi/comm.py
--rw-r--r--  2.0 unx    14596 b- defN 23-Apr-05 15:43 vqapi/exception.py
--rw-r--r--  2.0 unx    60270 b- defN 23-Apr-05 15:43 vqapi/services.py
--rw-r--r--  2.0 unx       79 b- defN 23-Apr-05 15:43 vqapi/types.py
--rw-r--r--  2.0 unx    13956 b- defN 23-Apr-05 15:43 vqapi/util.py
--rw-r--r--  2.0 unx      165 b- defN 23-Apr-05 15:43 vqapi/version.py
--rw-r--r--  2.0 unx    34260 b- defN 23-Apr-05 15:43 vqapi/vqclass.py
--rw-r--r--  2.0 unx    11536 b- defN 23-Apr-05 15:43 vqapi/vqquery.py
--rw-r--r--  2.0 unx     4604 b- defN 23-Apr-05 15:43 vqapi/xmldict.py
--rw-r--r--  2.0 unx        8 b- defN 23-Apr-05 15:43 vqapi/RequestsMonkeyPatch/__init__.py
--rw-r--r--  2.0 unx      138 b- defN 23-Apr-05 15:43 vqapi/RequestsMonkeyPatch/monkeypatch.py
--rw-r--r--  2.0 unx     2032 b- defN 23-Apr-05 15:43 vqapi/RequestsMonkeyPatch/requests_patch.py
--rw-r--r--  2.0 unx        0 b- defN 23-Apr-05 15:43 vqapi/tests/__init__.py
--rw-r--r--  2.0 unx      800 b- defN 23-Apr-05 15:43 vqapi/tests/conftest.py
--rw-rw-rw-  2.0 unx      254 b- defN 23-Apr-05 15:43 vqapi/tests/setup.cfg.sample
--rw-r--r--  2.0 unx      848 b- defN 23-Apr-05 15:43 vqapi/tests/test_bqapi.py
--rw-r--r--  2.0 unx      516 b- defN 23-Apr-05 15:43 vqapi/tests/test_bqclass.py
--rw-r--r--  2.0 unx     6626 b- defN 23-Apr-05 15:43 vqapi/tests/test_bqfeature.py
--rw-r--r--  2.0 unx     6645 b- defN 23-Apr-05 15:43 vqapi/tests/test_comm.py
--rw-r--r--  2.0 unx     8071 b- defN 23-Apr-05 15:43 vqapi/tests/test_util.py
--rw-r--r--  2.0 unx      575 b- defN 23-Apr-05 15:43 vqapi/tests/util.py
--rw-r--r--  2.0 unx      905 b- defN 23-Apr-05 15:43 viqi_api-0.6.4.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Apr-05 15:43 viqi_api-0.6.4.0.dist-info/WHEEL
--rw-r--r--  2.0 unx        6 b- defN 23-Apr-05 15:43 viqi_api-0.6.4.0.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2577 b- defN 23-Apr-05 15:43 viqi_api-0.6.4.0.dist-info/RECORD
-33 files, 300092 bytes uncompressed, 76245 bytes compressed:  74.6%
+Zip file size: 62435 bytes, number of entries: 21
+-rw-rw-rw-  2.0 unx      417 b- defN 23-Apr-07 18:10 vqapi/README.md
+-rw-r--r--  2.0 unx      251 b- defN 23-Apr-07 18:10 vqapi/__init__.py
+-rw-r--r--  2.0 unx     1746 b- defN 23-Apr-07 18:10 vqapi/blockable_module.py
+-rw-r--r--  2.0 unx    28745 b- defN 23-Apr-07 18:10 vqapi/bqclass.py
+-rw-r--r--  2.0 unx     1595 b- defN 23-Apr-07 18:10 vqapi/casauth.py
+-rw-r--r--  2.0 unx     6106 b- defN 23-Apr-07 18:10 vqapi/cmd.py
+-rw-r--r--  2.0 unx    50118 b- defN 23-Apr-07 18:10 vqapi/comm.py
+-rw-r--r--  2.0 unx    14598 b- defN 23-Apr-07 18:10 vqapi/exception.py
+-rw-r--r--  2.0 unx    61279 b- defN 23-Apr-07 18:10 vqapi/services.py
+-rw-r--r--  2.0 unx    13926 b- defN 23-Apr-07 18:10 vqapi/util.py
+-rw-r--r--  2.0 unx      165 b- defN 23-Apr-07 18:10 vqapi/version.py
+-rw-r--r--  2.0 unx    33507 b- defN 23-Apr-07 18:10 vqapi/vqclass.py
+-rw-r--r--  2.0 unx    11337 b- defN 23-Apr-07 18:10 vqapi/vqquery.py
+-rw-r--r--  2.0 unx     4604 b- defN 23-Apr-07 18:10 vqapi/xmldict.py
+-rw-rw-rw-  2.0 unx        8 b- defN 23-Apr-07 18:10 vqapi/RequestsMonkeyPatch/__init__.py
+-rw-rw-rw-  2.0 unx      138 b- defN 23-Apr-07 18:10 vqapi/RequestsMonkeyPatch/monkeypatch.py
+-rw-rw-rw-  2.0 unx     2010 b- defN 23-Apr-07 18:10 vqapi/RequestsMonkeyPatch/requests_patch.py
+-rw-r--r--  2.0 unx     1509 b- defN 23-Apr-07 18:10 viqi_api-0.6.4.1.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-07 18:10 viqi_api-0.6.4.1.dist-info/WHEEL
+-rw-r--r--  2.0 unx        6 b- defN 23-Apr-07 18:10 viqi_api-0.6.4.1.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     1624 b- defN 23-Apr-07 18:10 viqi_api-0.6.4.1.dist-info/RECORD
+21 files, 233781 bytes uncompressed, 59845 bytes compressed:  74.4%
```

## zipnote {}

```diff
@@ -6,20 +6,14 @@
 
 Filename: vqapi/blockable_module.py
 Comment: 
 
 Filename: vqapi/bqclass.py
 Comment: 
 
-Filename: vqapi/bqfeature.py.old
-Comment: 
-
-Filename: vqapi/bqnode.py.save
-Comment: 
-
 Filename: vqapi/casauth.py
 Comment: 
 
 Filename: vqapi/cmd.py
 Comment: 
 
 Filename: vqapi/comm.py
@@ -27,17 +21,14 @@
 
 Filename: vqapi/exception.py
 Comment: 
 
 Filename: vqapi/services.py
 Comment: 
 
-Filename: vqapi/types.py
-Comment: 
-
 Filename: vqapi/util.py
 Comment: 
 
 Filename: vqapi/version.py
 Comment: 
 
 Filename: vqapi/vqclass.py
@@ -54,47 +45,20 @@
 
 Filename: vqapi/RequestsMonkeyPatch/monkeypatch.py
 Comment: 
 
 Filename: vqapi/RequestsMonkeyPatch/requests_patch.py
 Comment: 
 
-Filename: vqapi/tests/__init__.py
-Comment: 
-
-Filename: vqapi/tests/conftest.py
-Comment: 
-
-Filename: vqapi/tests/setup.cfg.sample
-Comment: 
-
-Filename: vqapi/tests/test_bqapi.py
-Comment: 
-
-Filename: vqapi/tests/test_bqclass.py
-Comment: 
-
-Filename: vqapi/tests/test_bqfeature.py
-Comment: 
-
-Filename: vqapi/tests/test_comm.py
-Comment: 
-
-Filename: vqapi/tests/test_util.py
-Comment: 
-
-Filename: vqapi/tests/util.py
-Comment: 
-
-Filename: viqi_api-0.6.4.0.dist-info/METADATA
+Filename: viqi_api-0.6.4.1.dist-info/METADATA
 Comment: 
 
-Filename: viqi_api-0.6.4.0.dist-info/WHEEL
+Filename: viqi_api-0.6.4.1.dist-info/WHEEL
 Comment: 
 
-Filename: viqi_api-0.6.4.0.dist-info/top_level.txt
+Filename: viqi_api-0.6.4.1.dist-info/top_level.txt
 Comment: 
 
-Filename: viqi_api-0.6.4.0.dist-info/RECORD
+Filename: viqi_api-0.6.4.1.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## vqapi/__init__.py

```diff
@@ -1,11 +1,10 @@
 #
 
 
 from .cmd import bisque_argument_parser, bisque_config, bisque_session
 from .comm import *
 from .services import ResponseFile, ResponseFolder
-from .types import *
 from .vqclass import *
 
 # import logging
 # logging.getLogger(__name__).addHandler(logging.NullHandler())
```

## vqapi/blockable_module.py

```diff
@@ -1,13 +1,15 @@
 import collections
 import logging
-#import sys
 
 from vqapi import BQSession
 
+# import sys
+
+
 # logging.basicConfig(filename='BlockableModule.log',level=logging.DEBUG)   #!!!
 log = logging.getLogger("vqapi.blockable_module")
 
 
 class BlockableModule:
     """Base class for module that can run over blocks of parameters"""
```

## vqapi/bqclass.py

```diff
@@ -51,28 +51,23 @@
 __version__ = "0.1"
 __revision__ = "$Rev$"
 __date__ = "$Date$"
 __copyright__ = "Center for BioImage Informatics, University California, Santa Barbara"
 
 import inspect
 import io
+import json
 import logging
 import math
 import os
 import sys
 import tempfile
 
 from bq.metadoc.formats import Metadoc, anyxml_to_etree
 
-try:
-    import json
-except ImportError:
-    pass
-
-
 log = logging.getLogger("vqapi.class")
 
 __all__ = [
     "BQFactory",
     "BQNode",
     "BQImage",
     "BQResource",
@@ -187,17 +182,15 @@
     xmlfields = ["value", "type", "index"]
 
     # def __init__(self,  **kw):
     #    super(BQValue, self).__init__(**kw)
 
     def set_parent(self, parent):
         if self.index is not None:
-            parent.values.extend(
-                [None for x in range((self.index + 1) - len(parent.values))]
-            )
+            parent.values.extend([None for x in range((self.index + 1) - len(parent.values))])
             parent.values[self.index] = self
         else:
             parent.values.append(self)
 
     def initializeXml(self, xmlnode):
         super().initializeXml(xmlnode)
         try:
@@ -227,15 +220,15 @@
 
     xmltag = "resource"
     xmlfields = ["name", "type", "uri", "ts", "resource_uniq"]
     xmlkids = [
         "kids",
         "tags",
         "gobjects",
-    ]  #  'values'] handled differently
+    ]  # 'values'] handled differently
 
     def __repr__(self):
         return f"({self.xmltag}:{self.uri})"  # pylint: disable=no-member
 
     def __init__(self, *args, **kw):
         self.tags = []
         self.gobjects = []
@@ -333,31 +326,30 @@
         if len(self.values) == 1:
             return self.values[0].value
         return [x.value for x in self.values]
 
     def set_value(self, values):
         if not isinstance(values, list):
             values = [values]
-        self.values = [
-            BQValue(*v) if isinstance(v, tuple) else BQValue(v) for v in values
-        ]
+        self.values = [BQValue(*v) if isinstance(v, tuple) else BQValue(v) for v in values]
 
     value = property(get_value, set_value)
 
     def toetree(self, parent, baseuri):
         xmlkids = list(self.xmlkids)
         if len(self.values) <= 1:
             n = create_element(self, parent, baseuri)
         else:
             n = create_element(self, parent, baseuri)
             if "value" in n.attrib:
                 del n.attrib["value"]
             xmlkids.append("values")
         for kid_name in xmlkids:
             for x in getattr(self, kid_name, None):
+                print("Descending ", n, " with ", kid_name, " ", x)
                 toxmlnode(x, n, baseuri)
         return n
 
 
 ################################################################################
 # Image
 ################################################################################
@@ -368,15 +360,15 @@
     xmlfields = [
         "name",
         "value",
         "type",
         "uri",
         "ts",
         "resource_uniq",
-    ]  #  "x", "y","z", "t", "ch"  ]
+    ]  # ["x", "y","z", "t", "ch"]
     xmlkids = ["tags", "gobjects"]
 
     def __init__(self, *args, **kw):
         super().__init__(*args, **kw)
         self._geometry = None
         self._meta = None
         self._info = {}
@@ -408,19 +400,15 @@
                 geom.append(tn[0].get("value"))
             self._geometry = tuple(map(int, geom))
         return self._geometry
 
     def histogram(self):
         "returns image histogram"
         if self._histogram is None:
-            s = (
-                self.pixels()
-                .command("histogram", arguments="json")
-                .fetch(want_str=True)
-            )
+            s = self.pixels().command("histogram", arguments="json").fetch(want_str=True)
             h = json.loads(s)
             if "histogram" in h:
                 self._histogram = h["histogram"]
         return self._histogram
 
     def pixels(self):
         return BQImagePixels(self)
@@ -433,16 +421,15 @@
         self.image = image
         self.ops = []
 
     def _construct_url(self):
         """build the final url based on the operation"""
         image_service = self.image.session.service("image_service")
         return image_service.construct(
-            path="%s?%s"
-            % (self.image.resource_uniq, "&".join("%s=%s" % tp for tp in self.ops))
+            path="{}?{}".format(self.image.resource_uniq, "&".join("%s=%s" % tp for tp in self.ops))
         )
         # return session.service_url('image_service',
         #                           % (self.image.resource_uniq, '&'.join(self.ops)))
 
     def fetch(
         self, path=None, stream=False, want_str=False
     ):  # TODO: instead of want_str, need better way to infer return type (binary or str)
@@ -653,14 +640,15 @@
 
 # only does 2D version right now, polygon area is flawed if the edges are intersecting
 # implement better algorithm based on triangles
 class BQPolygon(BQGObject):
     """Polygon gobject resource"""
 
     xmltag = "polygon"
+
     # only does 2D version right now
     def perimeter(self):
         vx = self.verticesAsTuples()
         vx.append(vx[0])
         d = 0
         for i in range(0, len(vx) - 1):
             x1, y1, z1, t1 = vx[i]
@@ -708,17 +696,15 @@
     def perimeter(self):
         vx = self.verticesAsTuples()
         x1, y1, z1, t1 = vx[0]
         x2, y2, z2, t2 = vx[1]
         x3, y3, z3, t3 = vx[2]
         a = max(math.fabs(x1 - x2), math.fabs(y1 - y2))
         b = max(math.fabs(x1 - x3), math.fabs(y1 - y3))
-        return math.pi * (
-            3.0 * (a + b) - math.sqrt(10.0 * a * b + 3.0 * (a * a + b * b))
-        )
+        return math.pi * (3.0 * (a + b) - math.sqrt(10.0 * a * b + 3.0 * (a * a + b * b)))
 
     def area(self):
         vx = self.verticesAsTuples()
         x1, y1, z1, t1 = vx[0]
         x2, y2, z2, t2 = vx[1]
         x3, y3, z3, t3 = vx[2]
         a = max(math.fabs(x1 - x2), math.fabs(y1 - y2))
@@ -839,15 +825,15 @@
 
         resources[0].initialize()
         resources[0].xmltree = xmlResource
         return resources[0]
 
     def from_string(self, xmlstring):
         et = Metadoc(et=anyxml_to_etree(xmlstring))
-        return self.from_etree(et)
+        return self.from_etree(et.to_tagxml_etree())
 
     # Generation
 
     @classmethod
     def to_etree(self, dbo, parent=None, baseuri="", view=""):
         """Convert a BQObject to an etree object suitable for XML
         generation
```

## vqapi/casauth.py

```diff
@@ -12,15 +12,15 @@
         if strip:
             if "type" in tag.attrs and tag.attrs["type"] not in (
                 "text",
                 "password",
                 "hidden",
             ):
                 return False
-        return tag.has_key("name") and tag.has_key("value") # noqa
+        return tag.has_key("name") and tag.has_key("value")  # noqa
 
 
 def caslogin(session, caslogin, username, password, service=None):
     if service:
         params = {"service": service}
     else:
         params = None
```

## vqapi/cmd.py

```diff
@@ -1,14 +1,15 @@
 #!/usr/bin/env python
 import argparse
 import logging
 import os
 import posixpath
-#import sys
-#import time
+
+# import sys
+# import time
 from configparser import RawConfigParser
 
 import urllib3
 
 from .comm import BQSession
 
 # Check the directories in order for the config, the 1st one is the default for writing new config
@@ -18,36 +19,26 @@
     "~/bisque/config" if os.name == "nt" else "~/.bisque/config",
 ]
 
 
 def bisque_argument_parser(*args, **kw):
     parser = argparse.ArgumentParser(*args, **kw)
     parser.add_argument("-c", "--config", help="bisque config", default=None)
-    parser.add_argument(
-        "--profile", help="Profile to use in bisque config", default="default"
-    )
+    parser.add_argument("--profile", help="Profile to use in bisque config", default="default")
     parser.add_argument(
         "-n",
         "--dry-run",
         action="store_true",
         help="report actions w/o changes",
         default=False,
     )
-    parser.add_argument(
-        "-d", "--debug", nargs="?", help="set debug level: debug,info,warn,error"
-    )
-    parser.add_argument(
-        "--debug-file", help="output filename for debug messages", default=None
-    )
-    parser.add_argument(
-        "-q", "--quiet", action="store_true", help="print actions ", default=False
-    )
-    parser.add_argument(
-        "-a", "--credentials", help="A bisque login.. admin ", default=None
-    )
+    parser.add_argument("-d", "--debug", nargs="?", help="set debug level: debug,info,warn,error")
+    parser.add_argument("--debug-file", help="output filename for debug messages", default=None)
+    parser.add_argument("-q", "--quiet", action="store_true", help="print actions ", default=False)
+    parser.add_argument("-a", "--credentials", help="A bisque login.. admin ", default=None)
     parser.add_argument("--host", help="Default bisque server to connect to ")
     parser.add_argument("--user", help="User to  connect with ")
     parser.add_argument("--password", help="passwor to  connect with ")
     parser.add_argument("--alias", help="Use admin credentials to login as alias")
     # Local arguments
     return parser
 
@@ -79,19 +70,15 @@
             print(f"No or incomplete profile named {pargs.profile}")
 
     # if pargs.host:
     #    root = pargs.host
     if pargs.credentials and not (pargs.user or pargs.password):
         pargs.user, pargs.password = pargs.credentials.split(":")
     if not (pargs.host and pargs.user and pargs.password):
-        print(
-            "Please configure how to connect to bisque with profile {}".format(
-                pargs.profile
-            )
-        )
+        print(f"Please configure how to connect to bisque with profile {pargs.profile}")
         if write_config:
             if pargs.config is None:
                 pargs.config = CONFIG_PATHS[0]
             pargs.host = input(f"BisQue URL [{pargs.host}] ") or pargs.host
             pargs.user = input(f"username[{pargs.user}] ") or pargs.user
             pargs.password = input(f"password[{pargs.password}]: ") or pargs.password
             config_file = os.path.expanduser(pargs.config)
@@ -157,30 +144,25 @@
                 "info": logging.INFO,
                 "warn": logging.WARN,
                 "error": logging.ERROR,
             }.get(pargs.debug.lower(), logging.DEBUG)
         )
 
     if pargs.host and pargs.user and pargs.password:
-
         session = BQSession()
         urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)
         session.c.verify = False
         session = session.init_local(
             bisque_root=pargs.host,
             user=pargs.user,
             pwd=pargs.password,
             create_mex=False,
             as_user=pargs.alias,
         )
         if session is None:
-            print(
-                "Could not create bisque session with host={} user={}. Check your config".format(
-                    pargs.host, pargs.user
-                )
-            )
+            print(f"Could not create bisque session with host={pargs.host} user={pargs.user}. Check your config")
             return session
         if not pargs.quiet:
             print("Session for  ", pargs.host, " for user ", session.user, " created")
         session.parse_args = pargs
         session.server_version = "viqi1"
     return session
```

## vqapi/comm.py

```diff
@@ -60,31 +60,33 @@
 import posixpath
 import urllib.parse
 
 import requests
 from requests import Session
 from requests.adapters import HTTPAdapter
 from requests.auth import AuthBase, HTTPBasicAuth
-#from requests_cache import CachedSession
 
 # from requests.packages.urllib3.util.retry import Retry
 from urllib3 import Retry
 
+# from requests_cache import CachedSession
+
+
 # from requests_toolbelt import MultipartEncoder
 
 try:
     from collections import OrderedDict
 except ImportError:
     from ordereddict import OrderedDict
 
 from bq.metadoc.formats import InvalidFormat, Metadoc, anyxml_to_etree
 
+from .bqclass import BQFactory, BQNode
 from .exception import BQApiError, CommErrorFactory
 from .services import ServiceFactory
-from .types import BQFactory, BQNode
 from .util import is_uniq_code
 
 # from .RequestsMonkeyPatch import requests_patch#allows multipart form to accept unicode
 
 try:
     from .casauth import caslogin
 
@@ -110,17 +112,15 @@
                 return None
             if self.headers.get("x-viqi-content-type", "") == "application/xml+tag":
                 return Metadoc.from_tagxml(self.text)
             else:
                 return Metadoc.from_naturalxml(self.text)
         return None
     except InvalidFormat:
-        log.error(
-            "XML expected but got %s %s", self.headers["content-type"], self.content
-        )
+        log.error("XML expected but got %s %s", self.headers["content-type"], self.content)
         raise BQApiError(f"Bad xml content for request: {self.url}:{self.content} ")
 
 
 class MexAuth(AuthBase):
     """
     Bisque's Mex Authentication
     """
@@ -301,17 +301,15 @@
                 # f.write(r.content) # write in chunks
                 for block in r.iter_content(chunk_size=16 * 1024 * 1024):  # 16MB
                     f.write(block)
                 f.flush()
             return f.name
         else:
             if r.doc() is not None:
-                return (
-                    r.doc().to_tagxml()
-                )  # for backward compat... callers expect xml string, not Metadoc right now
+                return r.doc().to_tagxml()  # for backward compat... callers expect xml string, not Metadoc right now
             else:
                 return r.content
 
     def fetch(self, url, headers=None, path=None):
         return self.webreq(method="get", url=url, headers=headers, path=path)
 
     def push(
@@ -339,32 +337,28 @@
         @return returns either the contents of the rests or the file name if a path is provided
 
         @exception: BQApiError if the requests returns an error code and message
         """
         log.debug(f"POST {url} req {headers}")
 
         try:  # error checking
-            r = self.request(
-                method, url, data=content, headers=headers, files=files, timeout=timeout
-            )
+            r = self.request(method, url, data=content, headers=headers, files=files, timeout=timeout)
             r.raise_for_status()
         except requests.exceptions.HTTPError:
             log.exception(f"In push request: {method} {url} {r.content}")
             # raise BQApiError(r)
             raise CommErrorFactory.make(r)
 
         if path:
             with open(path, "wb") as f:
                 f.write(r.content)
             return f.name
         else:
             if r.doc() is not None:
-                return (
-                    r.doc().to_tagxml()
-                )  # for backward compat... callers expect xml string, not Metadoc right now
+                return r.doc().to_tagxml()  # for backward compat... callers expect xml string, not Metadoc right now
             else:
                 return r.content
 
 
 class BQSession:
     """
     Top level Bisque communication object
@@ -458,29 +452,27 @@
         #             if auth_type.lower () == "mex":
         #                 self.c.authenticate_mex (auth_token)
         #                 return True
         #         return False
 
     def _clean_mex(self):
         # remove any temp mex and build docs
-        #url = self.service_url("data_service")
+        # url = self.service_url("data_service")
         if self.delete_mex is not None:
             self.deletexml(self.delete_mex)
             self.delete_mex = None
         if self.delete_build is not None:
             self.deletexml(self.delete_build)
             self.delete_build = None
 
     def _check_session(self):
         """Used to check that session is actuall active"""
         auth = self.service("auth_service")
         try:
-            r = auth.get(
-                "session", render="doc"
-            )  # self.fetchxml (self.service_url("auth_service", 'session'))
+            r = auth.get("session", render="doc")  # self.fetchxml (self.service_url("auth_service", 'session'))
             users = r.findall("./user") if r else []
             return len(users) > 0
         except BQApiError:
             return False
 
     def setup_retry(
         self,
@@ -1121,17 +1113,15 @@
         append_mex(mex, ("gobject", gobjects))
         for elem in children:
             append_mex(mex, elem)
 
     ##############################
     # Mex
     ##############################
-    def update_mex(
-        self, status, tags=None, gobjects=None, children=None, reload=False, merge=False
-    ):
+    def update_mex(self, status, tags=None, gobjects=None, children=None, reload=False, merge=False):
         """save an updated mex with the addition
 
         @param status:  The current status of the mex
         @param tags: list of Metadoc|JSON dict objects (can be nested) of form { 'name': 'value', ... }
         @param gobjects: list of Metadoc|JSON dict objects (can be nested) of form { 'name': 'value', ... }
         @param children: list of tuple (type, obj array) i.e [('mex', [dict1, dict2, ...]), ('bla', [dict3, dict4, ...])]
         @param reload:
@@ -1150,14 +1140,15 @@
                 self.mex.get_attr("uri"), view="deep"
             )  # get old version of MEX, so it can be merged if needed
             mex.text = status
             bq5_merge = False  # do the merge here
         else:
             mex = Metadoc(tag="mex", value=status, uri=self.mex.get_attr("uri"))
             bq5_merge = not attr_only  # True  # let the server merge (deprecated!)
+
         # self.mex.value = status
         def append_mex(mex, type_tup):
             (
                 type_,
                 elems,
             ) = type_tup  # why was this type_ needed? can't we just use JSON encoded fragments?
             for tg in elems:
@@ -1196,17 +1187,15 @@
             attr_only="1" if attr_only else "0",
         )
         if reload and content is not None:
             self.mex = content
             return self.mex
         return None
 
-    def finish_mex(
-        self, status="FINISHED", tags=None, gobjects=None, children=None, msg=None
-    ):
+    def finish_mex(self, status="FINISHED", tags=None, gobjects=None, children=None, msg=None):
         """
         @param status:
         @param tags:
         @param gobject:
         @param children:
         @param msg:
 
@@ -1229,20 +1218,15 @@
                 merge=True,
             )
         except BQApiError as ce:
             log.error("Problem during finish mex %s", str(ce.response_headers))
             try:
                 return self.update_mex(
                     status="FAILED",
-                    tags=[
-                        {
-                            "error_message": "Error during saving (status %s)"
-                            % ce.response_code
-                        }
-                    ],
+                    tags=[{"error_message": "Error during saving (status %s)" % ce.response_code}],
                 )
             except Exception:
                 log.exception("Cannot finish/fail Mex ")
 
     def fail_mex(self, msg):
         """
         @param msg:
@@ -1322,15 +1306,15 @@
         """
         @param bqo:
         @param url:
         @param kw:
         @return
         """
         try:
-            #original = bqo
+            # original = bqo
 
             # Find an object (or parent with a valild uri)
             url = url or bqo.uri
             if url is None:
                 while url is None and bqo.parent:
                     bqo = bqo.parent
                     url = bqo.parent.uri
```

## vqapi/exception.py

```diff
@@ -6,15 +6,17 @@
 import random
 from importlib import import_module
 
 #################################################
 #  Future not ready http code
 #################################################
 
-http_code_future_not_ready = 321  # 307 does not work in most browsers as expected (yet); may be changed back to 307 once it does
+http_code_future_not_ready = (
+    321  # 307 does not work in most browsers as expected (yet); may be changed back to 307 once it does
+)
 
 
 #################################################
 #  Generic Exceptions
 #################################################
 
 # BQException (request etc from BQCommError) -> BQApiError (anything service, related request/response)
@@ -111,15 +113,17 @@
 
 class NoAuthorizationError(BQApiError):
     """User is not authorized for action
 
     Pass a redirect url if can be resolved
     """
 
-    http_code = 401  # TODO: SHOULD BE 403 because this is used for access forbidden; 401 is unauthorized (i.e., not logged in)
+    http_code = (
+        401  # TODO: SHOULD BE 403 because this is used for access forbidden; 401 is unauthorized (i.e., not logged in)
+    )
 
     def __init__(self, msg=None, redirect_url=None):
         super().__init__(
             msg
         )  # the celery serializer gets confused by this (https://stackoverflow.com/questions/64370063/django-celery-getting-pickling-error-on-throwing-custom-exception)
         self.redirect_url = redirect_url
         # if msg is not None:
@@ -502,17 +506,15 @@
     if isinstance(exc, FutureNotReadyError) and future is not None:
         # if this was a future not ready, indicate that in the headers and set up retry
         response.headers["x-viqi-future"] = future.get_future_id()
         response.location = f"/futures/{future.get_future_id()}/result"
         response.headers["Retry-After"] = str(future.expected_duration())
 
     if isinstance(exc, BQApiError):
-        response.headers[
-            "x-viqi-exception"
-        ] = f"{exc.__class__.__module__}.{exc.__class__.__qualname__}"
+        response.headers["x-viqi-exception"] = f"{exc.__class__.__module__}.{exc.__class__.__qualname__}"
     response.headers["Content-Type"] = "application/json"
     if isinstance(exc, BQException):
         response.status_code = exc.http_code
         response.headers["x-viqi-exception-msg"] = getattr(exc, "content", "")
     elif isinstance(exc, NotImplementedError):
         response.status_code = 501
     else:
```

## vqapi/services.py

```diff
@@ -1,35 +1,36 @@
 # pylint: disable=wrong-import-order,wrong-import-position
-#import functools
+# import functools
 import hashlib
 import io
 import json
 import logging
 import os
+import pickle
 import posixpath
 import random
 import shutil
 import string
 import tarfile
 import tempfile
 import time
-import tifffile
 import urllib.parse
-import pickle
-#from pickle import dumps, loads
-from typing import BinaryIO, Callable, Dict
+
+# from pickle import dumps, loads
+from typing import BinaryIO, Callable, Dict, Optional
 from urllib.parse import parse_qsl, urlparse
 
 import boto3
 import botocore
 import requests
 import tenacity
+import tifffile
+from bq.metadoc.formats import Metadoc
 from requests_toolbelt import MultipartEncoder
 
-from bq.metadoc.formats import Metadoc
 from vqapi.exception import http_code_future_not_ready
 
 from .exception import BQApiError, FutureNotFoundError, code_to_exception
 from .util import is_uniq_code, normalize_unicode
 
 # from botocore.credentials import RefreshableCredentials
 # from botocore.session import get_session
@@ -125,17 +126,15 @@
         return outname
 
     def force_to_filepath(self):
         "force this file into a locally accessible file and return its path"
         if self.fpath is not None:
             return self.fpath
         else:
-            with tempfile.NamedTemporaryFile(
-                mode="w+b", prefix="viqicomm", delete=False
-            ) as fout:  # who deletes this?
+            with tempfile.NamedTemporaryFile(mode="w+b", prefix="viqicomm", delete=False) as fout:  # who deletes this?
                 shutil.copyfileobj(self.stream, fout)
                 return fout.name
 
 
 class ResponseFolder:
     """
     Class to return folder structure. Can be used as context manager.
@@ -177,17 +176,15 @@
     def force_to_filepath(self):
         "force this folder structure into a locally accessible (tar) file and return its path"
         with tempfile.NamedTemporaryFile(
             mode="w+b", prefix="viqicomm", suffix=".tar", delete=False
         ) as fout:  # who deletes this?
             if isinstance(self.stream, str):
                 # folder path => package it as single tar file
-                with tarfile.open(
-                    fileobj=fout, mode="w"
-                ) as tout:  # TODO: could compress here
+                with tarfile.open(fileobj=fout, mode="w") as tout:  # TODO: could compress here
                     tout.add(self.stream, os.path.basename(self.stream), recursive=True)
             else:
                 # is alread tarfile obj => copy to actual file
                 shutil.copyfileobj(self.stream.fileobj, fout)
         return fout.name
 
 
@@ -250,21 +247,17 @@
         # no longer in session https://github.com/requests/requests/issues/3341
         timeout = kw.pop("timeout", self.timeout)
         headers = kw.pop("headers", self.session.c.headers)
         data = kw.get("data")
         if isinstance(data, str):  # hacky way to guess content type
             data = data.lstrip()
             if data[0] == "<":
-                headers[
-                    "Content-Type"
-                ] = "text/xml"  # TODO: -------------- use formatters on kw['data']!!!!
+                headers["Content-Type"] = "text/xml"  # TODO: -------------- use formatters on kw['data']!!!!
             elif data[0] in ("{", "["):
-                headers[
-                    "Content-Type"
-                ] = "application/json"  # TODO: -------------- use formatters on kw['data']!!!!
+                headers["Content-Type"] = "application/json"  # TODO: -------------- use formatters on kw['data']!!!!
         #         if render in ("xml", "etree", "doc"):
         #             headers["Accept"] = "text/xml"
         if render in ("json",):
             headers["Accept"] = "application/json"
         else:
             headers["Accept"] = "text/xml"  # default xml transmission
         # ignore any format request because it is handled via render and headers
@@ -285,36 +278,27 @@
     def fetch(self, path=None, params=None, render=None, **kw):
         return self.request(path=path, params=params, render=render, **kw)
 
     def get(self, path=None, params=None, render=None, **kw):
         return self.request(path=path, params=params, render=render, **kw)
 
     def post(self, path=None, params=None, render=None, **kw):
-        return self.request(
-            path=path, params=params, render=render, method="post", **kw
-        )
+        return self.request(path=path, params=params, render=render, method="post", **kw)
 
     def put(self, path=None, params=None, render=None, **kw):
         return self.request(path=path, params=params, render=render, method="put", **kw)
 
     def patch(self, path=None, params=None, render=None, **kw):
-        return self.request(
-            path=path, params=params, render=render, method="patch", **kw
-        )
+        return self.request(path=path, params=params, render=render, method="patch", **kw)
 
     def delete(self, path=None, params=None, render=None, **kw):
-        return self.request(
-            path=path, params=params, render=render, method="delete", **kw
-        )
+        return self.request(path=path, params=params, render=render, method="delete", **kw)
 
     def fetch_file(self, path=None, params=None, render=None, localpath=None, **kw):
-        with self.fetch(
-            path=path, params=params, render=render, stream=True, **kw
-        ) as response:
-
+        with self.fetch(path=path, params=params, render=render, stream=True, **kw) as response:
             if response.status_code != requests.codes.ok:  # pylint: disable=no-member
                 raise BQApiError(response)
 
             # OK response download
             original_length = content_left = response.headers.get("content-length")
             # log.debug('content-length: %s', original_length)
             content_md5 = response.headers.get("x-content-md5")
@@ -374,23 +358,19 @@
             retry_time = int(response.headers.get("Retry-After", 5))
             res = self._wait_for_future(fut, retry_time)
             # replace the original future response with a new response with OK code and result doc
             # TODO: how to do this properly?
             response = FutureResponse(200, res)
 
         else:
-            while (
-                response.status_code == http_code_future_not_ready
-            ):  # could also be one of the retry-futures (321)
+            while response.status_code == http_code_future_not_ready:  # could also be one of the retry-futures (321)
                 retry_time = int(response.headers.get("Retry-After", 5))
                 retry_url_toks = urlparse(response.headers.get("Location"))
                 time.sleep(retry_time)
-                path_without_service = "/".join(
-                    retry_url_toks.path.strip("/").split("/")[1:]
-                )  # assume same service
+                path_without_service = "/".join(retry_url_toks.path.strip("/").split("/")[1:])  # assume same service
                 response = self.request(
                     path=path_without_service,
                     params=dict(parse_qsl(retry_url_toks.query)),
                     method=method,
                     render=render,
                     future_wait=False,
                     **kw,
@@ -407,59 +387,49 @@
             log.warn("use of render=etree deprecated")
             return Metadoc.convert_back(res.doc())
         elif render == "json":
             return json.loads(res.text) if res.text else res.text
         else:
             return res
 
-    def request(
-        self, path=None, params=None, method="get", render=None, future_wait=True, **kw
-    ):
+    def request(self, path=None, params=None, method="get", render=None, future_wait=True, **kw):
         """
         @param path: a path relative to service (maybe a string or list)
         @param params: a diction of value to encode as params
         @param method: request type (get, put, post, etc)
         @param render: 'doc'/'etree'/'xml' to request doc response, 'json' for JSON response
         @param future_wait: if true, wait for result in case future came back; if false, return even if future doc
         @return a request.response (INDEPENDENT OF render!)
         """
         # enable redirects again; futures use code 321 which is not affected by requests redirect handling
         #         kw["allow_redirects"] = kw.get(
         #             "allow_redirects", False
         #         )  # turn off redirects by default as it will interfere with future handling
-        response = super().request(
-            path=path, params=params, method=method, render=render, **kw
-        )
+        response = super().request(path=path, params=params, method=method, render=render, **kw)
 
         # handle two special cases: (1) exception came back, (2) future came back
         self._reraise_exception(response)
         if future_wait:
-            response = self._ensure_future_result(
-                response, method=method, render=render, **kw
-            )
+            response = self._ensure_future_result(response, method=method, render=render, **kw)
 
         return response
 
 
 class AdminProxy(FuturizedServiceProxy):
     def login_as(self, user_name):
         data = self.session.service("meta")
-        userxml = data.fetch(
-            "user", params={"name": user_name, "wpublic": 1}, render="doc"
-        )
+        userxml = data.fetch("user", params={"name": user_name, "wpublic": 1}, render="doc")
         user_uniq = userxml.find(f"user[@name='{user_name}']")
         if user_uniq is not None:
             user_uniq = user_uniq.get("resource_uniq")
             response = self.fetch(f"user/{user_uniq}/login")
             response.raise_for_status()
 
             # check the login succeded
-            user_session = self.session.service("auth_service").get(
-                "session", render="doc"
-            )
+            user_session = self.session.service("auth_service").get("session", render="doc")
             user_id = user_session.find("user").get("value")
             # user_id is /<user_uniq"
             if user_id[1:] == user_uniq:
                 return user_uniq
 
         # login failed
         return None
@@ -513,17 +483,15 @@
 
         if isinstance(blob, str):
             with open(blob, "rb") as fh:
                 filedata = fh.read()
         else:
             filedata = pickle.dumps(blob)
 
-        res = self.post(
-            path, headers={"Content-Type": "application/octet-stream"}, data=filedata
-        )
+        res = self.post(path, headers={"Content-Type": "application/octet-stream"}, data=filedata)
 
         # prep outputs
         code_to_exception(res)
 
     def delete_blob(self, path: str):
         """Delete binary resource at given path.
 
@@ -716,31 +684,29 @@
 
         if dstpath[0] != "/":  # NOT absolute upload, join with def
             return posixpath.join(self.upload_default_mount, dstpath)
 
         return dstpath
 
     # @functools.lru_cache(maxsize=None)
-    def transfer_protocol_info(self, path: str = None, protocol: str = None) -> Dict:
+    def transfer_protocol_info(self, path: str = None, protocol: str = None) -> Optional[Metadoc]:
         """Return proto info for best transfer_protocol
 
         Args:
             path : the destination storepath
         Returns:
            A proto_info dict: with protocol specific information
         """
         if path is None:
-            path = set.update_prefix
+            path = self.upload_prefix
         if path[0] == "/":
             path = path[1:]
 
         dirpath = os.path.dirname(path)
-        mount = dirpath.split("/")[
-            0
-        ]  # 'home/hello/aaa.jpg' -> ['home', 'hello', 'aaa.jpg']
+        mount = dirpath.split("/")[0]  # 'home/hello/aaa.jpg' -> ['home', 'hello', 'aaa.jpg']
         if (mount, protocol) in self.protocol_info_map:
             return self.protocol_info_map[(mount, protocol)]
 
         if protocol is not None:
             available_protocols = [Metadoc.create_doc("prototcol", type=protocol)]
         else:
             protocols = self.fetch(posixpath.join("/transfer_protocol", dirpath))
@@ -798,17 +764,17 @@
         protocol: str = None,
     ):
         if srcpath is None and hasattr(fileobj, "name"):
             srcpath = fileobj.name
         dstpath = self.destination_path(srcpath, dstpath)
         transfer_info = self.transfer_protocol_info(path=dstpath, protocol=protocol)
         # log.info("TRANS %s", str(transfer_info))
-        protocol = transfer_info.path_query("protocol")[0]
         # Use the protocol to  find a method to transfer the file
         if transfer_info is not None:
+            protocol = transfer_info.path_query("protocol")[0]
             transfer_fct = getattr(self, "transfer_" + protocol.attrib["type"])
             if transfer_fct is not None:
                 return transfer_fct(
                     fileobj=fileobj,
                     dstpath=dstpath,
                     xml=xml,
                     callback=callback,
@@ -834,15 +800,15 @@
         if xml is not None:
             fields["file_resource"] = (None, xml, "application/xml")
         if fields:
             # https://github.com/requests/toolbelt/issues/75
             m = MultipartEncoder(fields=fields)
             m._read = m.read  # pylint: disable=protected-access
             # filesize = os.fstat (fileobj).st_size
-            #haveread = 0
+            # haveread = 0
 
             def reader(size):
                 buff = m._read(8192 * 1024)  # 8MB
                 # haveread += 8192
                 if callable(callback):
                     callback(len(buff))
                 return buff
@@ -853,17 +819,15 @@
                 "transfer_" + id_generator(),
                 data=m,
                 headers={"Accept": "text/xml", "Content-Type": m.content_type},
             )
             code_to_exception(response)
             return response.doc()
 
-    def transfer_binary(
-        self, fileobj, dstpath, xml=None, callback=None, transfer_info=None
-    ):
+    def transfer_binary(self, fileobj, dstpath, xml=None, callback=None, transfer_info=None):
         response = self.post(
             posixpath.join("transfer_direct", dstpath[1:]),
             data=fileobj,
             headers={"Content-Type": "application/octet-stream"},
         )
         code_to_exception(response)
 
@@ -937,14 +901,16 @@
                     filename,
                     fileobj,
                 )
                 if s3client is None:
                     s3client = self._s3_session(s3_info["Credentials"])
 
                 try:
+                    if not self._s3_dir_exists(s3client, s3_info, partial_path):
+                        self._s3_create_dirs(s3client, s3_info, partial_path)
                     s3client.upload_fileobj(
                         fileobj,
                         Bucket=s3_info["Destination"]["S3"]["Bucket"],
                         Key=posixpath.join(
                             s3_info["Destination"]["S3"]["Folder"],
                             partial_path,
                             filename,
@@ -980,42 +946,80 @@
             # register the uploaded file with xml if available
             blobs = self.session.service("blobs")
             if isinstance(xml, str):
                 xml = Metadoc.from_naturalxml(xml)
 
             try:
                 time.sleep(2)
-                for attempt in tenacity.Retrying(
-                    stop=tenacity.stop_after_attempt(3), wait=tenacity.wait_fixed(2)
-                ):
+                for attempt in tenacity.Retrying(stop=tenacity.stop_after_attempt(3), wait=tenacity.wait_fixed(2)):
                     log.info(f"REGISTER {dstpath}")
                     blobdoc = blobs.register(path=dstpath, resource=xml)
                     return blobdoc
             except tenacity.RetryError:
                 log.error("Regsitration failed after upload")
 
         except boto3.exceptions.S3UploadFailedError:
             log.exception("During upload of %s", filename)
         return None
 
+    def _s3_create_dirs(self, s3client, s3_info: dict, path: str):
+        """Ensure directory exists and has proper metadata (permissions)"""
+        head, tail = posixpath.split(path)
+        if not tail:  # special case for trailing '/'
+            head, tail = posixpath.split(head)
+        if head and tail:
+            # check if head exists
+            if not self._s3_dir_exists(s3client, s3_info, head):
+                # log.debug("recurse %s", head)
+                self._s3_create_dirs(s3client, s3_info, head)
+        #
+        self._s3_mkdir(s3client, s3_info, path)
+
+    def _s3_dir_exists(self, s3client, s3_info, dirpath):
+        """Check if user rooted directory exists"""
+        try:
+            # log.debug("s3_direxists %s", dirpath)
+            s3client.head_object(
+                Bucket=s3_info["Destination"]["S3"]["Bucket"],
+                Key=posixpath.join(s3_info["Destination"]["S3"]["Folder"], dirpath, ""),
+            )
+            return True
+        except botocore.exceptions.ClientError as error:
+            code = error.response["Error"]["Code"]
+            log.debug("s3direxists error %s", code)
+        return False
+
+    def _s3_mkdir(self, s3client, s3_info, dirpath):
+        try:
+            # log.debug("s3_mkdir %s ", dirpath)
+            s3client.put_object(
+                Bucket=s3_info["Destination"]["S3"]["Bucket"],
+                Key=posixpath.join(s3_info["Destination"]["S3"]["Folder"], dirpath, ""),
+                Metadata={
+                    "file-owner": s3_info["Destination"]["S3"]["Uid"],
+                    "file-group": s3_info["Destination"]["S3"]["Gid"],
+                },
+            )
+        except botocore.exceptions.ClientError as error:
+            code = error.response["Error"]["Code"]
+            log.debug("ended on %s", code)
+
     def _s3_session(self, s3_info: Dict):
         """Create a long-lasting s3 Session suitable for caching
         Args:
            s3_info : {"AccessKeyId": "ID",
                        "SessionToken": "Token", "SecretAccessKey":
                        "Secret", "Expiration": "Expires"}
 
         Returns:
           a S3 boto client
         TODO :  Utilize a refreshable credential provider
                 https://stackoverflow.com/questions/61899028/where-can-i-find-the-documentation-for-writing-custom-aws-credential-provider-us
         """
-        session = (
-            boto3.session.Session()
-        )  # see https://github.com/boto/boto3/issues/801
+        session = boto3.session.Session()  # see https://github.com/boto/boto3/issues/801
         s3client = session.client(
             "s3",
             aws_access_key_id=s3_info["AccessKeyId"],
             aws_secret_access_key=s3_info["SecretAccessKey"],
             aws_session_token=s3_info["SessionToken"],
         )
         return s3client
@@ -1127,17 +1131,15 @@
 
     def delete_member(self, dataset_uniq, resource_uniq, **kw):
         """Delete a member..
         @return new dataset if success or None
         """
         data = self.session.service("data_service")
         dataset = data.fetch(dataset_uniq, params={"view": "full"}, render="doc")
-        members = dataset.path_query(
-            'value[text()="%s"]' % data.construct(resource_uniq)
-        )
+        members = dataset.path_query('value[text()="%s"]' % data.construct(resource_uniq))
         for member in members:
             member.delete()
         if len(members):
             return data.put(dataset_uniq, data=dataset, render="doc")
         return None
 
 
@@ -1216,17 +1218,15 @@
         # prep outputs
         code_to_exception(res)
 
         return res.doc()
 
     def request(self, path=None, params=None, method="get", render=None, **kw):
         # TODO: add real api fct
-        res = super().request(
-            path=path, params=params, method=method, render=render, **kw
-        )
+        res = super().request(path=path, params=params, method=method, render=render, **kw)
         return self._prep_result(res, render)
 
 
 class TableProxy(FuturizedServiceProxy):
     def load_array(self, table_uniq, path, slices=None, want_info=False):
         """
         Load array from BisQue.
@@ -1275,21 +1275,17 @@
     def store_array(self, array, storepath, name) -> Metadoc:
         """
         Store numpy array or record array in BisQue and return resource doc.
         """
         try:
             dirpath = tempfile.mkdtemp()
             # (1) store array as HDF5 file
-            out_name = (
-                name + ".h5" if not name.endswith((".h5", ".hdf5")) else name
-            )  # importer needs extension .h5
+            out_name = name + ".h5" if not name.endswith((".h5", ".hdf5")) else name  # importer needs extension .h5
             out_file = os.path.join(dirpath, out_name)
-            with tables.open_file(
-                out_file, "w", filters=tables.Filters(complevel=5)
-            ) as h5file:  # compression level 5
+            with tables.open_file(out_file, "w", filters=tables.Filters(complevel=5)) as h5file:  # compression level 5
                 if array.__class__.__name__ == "recarray":
                     h5file.create_table(h5file.root, name, array)
                 elif array.__class__.__name__ == "ndarray":
                     h5file.create_array(h5file.root, name, array)
                 else:
                     raise BQApiError("unknown array type")  # TODO: more specific error
             # (2) call bisque blob service with file
@@ -1303,17 +1299,15 @@
             shutil.rmtree(dirpath)
 
     def load_table(self, table_uniq, path, slices=None, as_dataframe=True):
         """
         Load table as a numpy recarray or pandas dataframe.
         """
         ndarr, info = self.load_array(table_uniq, path, slices, want_info=True)
-        res = np.core.records.fromarrays(
-            ndarr.transpose(), names=info["headers"], formats=info["types"]
-        )
+        res = np.core.records.fromarrays(ndarr.transpose(), names=info["headers"], formats=info["types"])
         if as_dataframe is True:
             res = pd.DataFrame.from_records(res)
         return res
 
     def store_table(self, table, storepath, name) -> Metadoc:
         """
         Store numpy recarray or pandas dataframe in BisQue and return resource doc.
@@ -1333,37 +1327,30 @@
             self.image_service = image_service
             self.image_uniq = image_uniq
             self.ops = []
 
         def _construct_url(self):
             """build the final url based on the operation"""
             return self.image_service.construct(
-                path="%s?%s"
-                % (self.image.get_docid(), "&".join("%s=%s" % tp for tp in self.ops))
+                path="{}?{}".format(self.image.get_docid(), "&".join("%s=%s" % tp for tp in self.ops))
             )
 
         # TODO: image_fetch instead of want_str, need better way to infer return type (binary or str)
         def fetch(self, path=None, stream=False, want_str=False):
             """resolve the current and fetch the pixel"""
             # url = self._construct_url()
             if path is not None:
-                response = self.image_service.fetch_file(
-                    path=self.image_uniq, params=self.ops, localpath=path
-                )
+                response = self.image_service.fetch_file(path=self.image_uniq, params=self.ops, localpath=path)
             else:
-                response = self.image_service.fetch(
-                    self.image_uniq, params=self.ops, stream=stream
-                )
+                response = self.image_service.fetch(self.image_uniq, params=self.ops, stream=stream)
                 return response.text if want_str else response.content
 
         def command(self, operation, arguments=""):
             arguments = "" if arguments is None else arguments
-            self.ops.append(
-                (operation, arguments)
-            )  # In case None is passed .. requests library removes
+            self.ops.append((operation, arguments))  # In case None is passed .. requests library removes
             return self
 
         def slice(self, x="", y="", z="", t=""):
             """Slice the current image"""
             return self.command("slice", f"{x},{y},{z},{t}")
 
         def format(self, fmt):
@@ -1382,17 +1369,15 @@
         def info(self):
             return self.command("info")
 
         def asarray(self):
             # Force format to be tiff by removing any format and append format tiff
             self.ops = [tp for tp in self.ops if tp[0] != "format"]
             self.format("tiff")
-            with self.image_service.fetch(
-                    path=self.image_uniq, params=self.ops, stream=True
-            ) as response:
+            with self.image_service.fetch(path=self.image_uniq, params=self.ops, stream=True) as response:
                 # response.raw.decode_content = True
                 return tifffile.imread(io.BytesIO(response.content))
 
         def savearray(self, fname, imdata=None, imshape=None, dtype=None, **kwargs):
             import_service = self.image_service.session.service("import_service")
             imfile = tempfile.mkstemp(suffix=".tiff")
             tifffile.imsave(imfile, imdata, imshape, dtype, **kwargs)
@@ -1414,44 +1399,36 @@
         return ImageProxy.ImagePixels(self, image_uniq)
 
 
 class ExportProxy(FuturizedServiceProxy):
     valid_param = {"files", "datasets", "dirs", "urls", "users", "compression"}
 
     def fetch_export(self, **kw):
-        params = {
-            key: val
-            for key, val in list(kw.items())
-            if key in self.valid_param and val is not None
-        }
+        params = {key: val for key, val in list(kw.items()) if key in self.valid_param and val is not None}
         response = self.fetch("stream", params=params, stream=kw.pop("stream", True))
         return response
 
     def fetch_export_local(self, localpath, stream=True, **kw):
         response = self.fetch_export(stream=stream, **kw)
         if response.status_code == requests.codes.ok:
             with open(localpath, "wb") as f:
                 shutil.copyfileobj(response.raw, f)
         return response
 
 
 class DataProxy(FuturizedServiceProxy):
     # TODO: add real API fcts
-    def request(
-        self, path=None, params=None, method="get", render="doc", view=None, **kw
-    ):
+    def request(self, path=None, params=None, method="get", render="doc", view=None, **kw):
         if view is not None:
             if isinstance(view, list):
                 view = ",".join(view)
             params = params or {}
             params["view"] = view
 
-        res = super().request(
-            path=path, params=params, method=method, render=render, **kw
-        )
+        res = super().request(path=path, params=params, method=method, render=render, **kw)
 
         # prep outputs
         code_to_exception(res)
 
         return self._prep_result(res, render)
 
     def fetch(self, path=None, params=None, render="doc", **kw):
@@ -1491,19 +1468,15 @@
             >>> dir_service.create_container('store://mymount/my/path', 'new_container', container_type='tablecontainer')
         """
         # prep inputs
         path = _prepare_mountpath(path)
 
         res = self.post(
             path,
-            data=Metadoc.from_naturalxml(
-                '<dir name="{name}" type="{type}" />'.format(
-                    name=name, type=container_type
-                )
-            ),
+            data=Metadoc.from_naturalxml(f'<dir name="{name}" type="{container_type}" />'),
         )
 
         # prep outputs
         code_to_exception(res)
 
     def list_files(
         self,
```

## vqapi/util.py

```diff
@@ -4,20 +4,20 @@
 
 # import urllib
 # import urlparse
 # import time
 import urllib.parse
 
 import shortuuid
-
 from bq.metadoc import Metadoc
 
 log = logging.getLogger("vqapi.util")
 ALLOWED = shortuuid.get_alphabet()
 
+
 # TODO: remove this and include utils package instead
 def is_uniq_code(uniq, version=None):
     """Check that the code is a bisque uniq code
 
     @param uniq: The uniq code
     @param version: Test for a particular version:
     @return:  The version of the code or None
@@ -172,17 +172,15 @@
     @return XML content  when upload ok
 
     @exceptions comm.BQApiError - if blob is failed to be posted
     """
     # content = session.postblob(localfile, xml=resource)
     import_service = session.service("import")
     resource = Metadoc.convert(resource)
-    content = import_service.transfer_file(
-        localfile, dstpath=destdir, xml=resource, protocol="binary"
-    )
+    content = import_service.transfer_file(localfile, dstpath=destdir, xml=resource, protocol="binary")
 
     # content = ET.XML(content)
     # print ("CONENT", content)
     # content = Metadoc.convert_to_etree(content)
     return content
     # if len(content) < 1:  # when would this happen
     #    return None
@@ -351,17 +349,15 @@
     @param: dest -
     @param: uselocalpath- (default: False)
 
     @return
     """
     image = session.load(uri).pixels().info()
     # fileName = ET.XML(image.fetch()).xpath('//tag[@name="filename"]/@value')[0]
-    fileName = session.factory.string2etree(image.fetch()).findall(
-        './/tag[@name="filename"]'
-    )[0]
+    fileName = session.factory.string2etree(image.fetch()).findall('.//tag[@name="filename"]')[0]
     fileName = fileName.get("value")
 
     ip = session.load(uri).pixels().format("tiff")
 
     if uselocalpath:
         ip = ip.localpath()
 
@@ -436,15 +432,15 @@
 
 def as_flat_dict_tag_value(xmltree):
     def _xml2d(e, d, path=""):
         for child in e:
             name = "{}{}".format(path, child.get("name", ""))
             value = child.get("value", None)
             if value is not None:
-                if  name not in d:
+                if name not in d:
                     d[name] = value
                 else:
                     if isinstance(d[name], list):
                         d[name].append(value)
                     else:
                         d[name] = [d[name], value]
             d = _xml2d(child, d, path="{}{}/".format(path, child.get("name", "")))
@@ -456,15 +452,15 @@
 def as_flat_dicts_node(xmltree):
     def _xml2d(e, d, path=""):
         for child in e:
             name = "{}{}".format(path, child.get("name", ""))
             # value = child.get('value', None)
             value = child
             # if value is not None:
-            if  name not in d:
+            if name not in d:
                 d[name] = value
             else:
                 if isinstance(d[name], list):
                     d[name].append(value)
                 else:
                     d[name] = [d[name], value]
             d = _xml2d(child, d, path="{}{}/".format(path, child.get("name", "")))
```

## vqapi/version.py

```diff
@@ -1,4 +1,4 @@
 # file generated by setuptools_scm
 # don't change, don't track in version control
-__version__ = version = '0.6.4.0'
-__version_tuple__ = version_tuple = (0, 6, 4, 0)
+__version__ = version = '0.6.4.1'
+__version_tuple__ = version_tuple = (0, 6, 4, 1)
```

## vqapi/vqclass.py

```diff
@@ -1,24 +1,26 @@
 import copy
 import inspect
 import json
 import logging
-import time
 import sys
+import time
 from typing import List, Tuple
 
 from bq.metadoc.formats import Metadoc, anyxml_to_etree
+
 from vqapi import BQSession
 from vqapi.exception import BQApiError
 from vqapi.vqquery import get_provenance, run_sparql_query
 
 log = logging.getLogger("vqapi.vqclass")
 
+
 def get_header(res, name):
-    return res.headers[name].lstrip("W/")[
+    return res.headers.get(name, "").lstrip("W/")[
         1:-1
     ]  # remove entity tag and quotes (why is this not done by pyramid?)
 
 
 def _get_param_types(param, default="string"):
     param_type = param.get_attr("type", default)
     if param_type == "resource":
@@ -105,42 +107,36 @@
 @copy_as_not_impl(Metadoc)
 class VQResource:
     """
     Class to store any ViQi-backed resource doc;
     same interface as Metadoc but has extra functions depending on resource type.
     """
 
-    def __init__(
-        self, sess: "VQSession", doc_uniq: str = None, doc_version: str = None, **attrs
-    ):
+    def __init__(self, sess: "VQSession", doc_uniq: str = None, doc_version: str = None, **attrs):
         tag = self.resource_type
         self._doc_uniq = doc_uniq
         self._doc_version = doc_version
         self._doc = Metadoc(tag=tag, **attrs)
         self._doc_lvls = 0
         self._sess = sess
         self._meta = sess.service("meta")
 
     @staticmethod
     def load(sess: "VQSession", uniq: str) -> "VQResource":
         return sess.load(uniq)
 
     @classmethod
     def find(cls, sess: "VQSession", **kwargs) -> "VQResource":
-        raise NotImplementedError(
-            f"find operation not implemented for resource type {cls.resource_type}"
-        )
+        raise NotImplementedError(f"find operation not implemented for resource type {cls.resource_type}")
 
     def _refresh(self, lvls: int):
         view = "short" if lvls == 1 else ("full" if lvls == 2 else "deep")
         if self._doc_uniq is not None:
             if lvls <= self._doc_lvls:
-                headers = {
-                    "If-None-Match": self._doc_version
-                }  # fetch only if newer version available
+                headers = {"If-None-Match": self._doc_version}  # fetch only if newer version available
             else:
                 headers = {}  # fetch always, need more levels
             res = self._meta.request(
                 method="get",
                 path="/" + self._doc_uniq,
                 params={"view": view},
                 headers=headers,
@@ -264,22 +260,18 @@
             output_name (str): name of output
 
         Returns:
             object: output value (may be any type, including VQResource subtype)
         """
         self.wait()
         self._refresh(lvls=sys.maxsize)
-        mex_out = self._doc.path_query(
-            f'/mex/outputs//{output_name}[not(@type) or @type != "group"]'
-        )
+        mex_out = self._doc.path_query(f'/mex/outputs//{output_name}[not(@type) or @type != "group"]')
         if len(mex_out) == 0:
             if len(self._doc.path_query("/mex/mex")) > 0:
-                raise BQApiError(
-                    "this is a mex with submexes; please use get_sub_output or get_sub_outputs"
-                )
+                raise BQApiError("this is a mex with submexes; please use get_sub_output or get_sub_outputs")
             else:
                 raise BQApiError(f'output "{output_name}" not found')
         out_arg = mex_out[0]
         return self._get_output_single(
             out_arg_type=out_arg.get_attr("type", "doc"),
             out_arg_value=out_arg.get_value(),
             out_docid=self._doc_uniq,
@@ -294,17 +286,15 @@
             qc_name (str): name of qc output
 
         Returns:
             object: output value (may be any type, including VQResource subtype)
         """
         self.wait()
         self._refresh(lvls=sys.maxsize)
-        mex_out = self._doc.path_query(
-            f'/mex/qc//{qc_name}[not(@type) or @type != "group"]'
-        )
+        mex_out = self._doc.path_query(f'/mex/qc//{qc_name}[not(@type) or @type != "group"]')
         if len(mex_out) == 0:
             raise BQApiError(f'qc data "{qc_name}" not found')
         out_arg = mex_out[0]
         return self._get_output_single(
             out_arg_type=out_arg.get_attr("type", "doc"),
             out_arg_value=out_arg.get_value(),
             out_docid=self._doc_uniq,
@@ -326,17 +316,15 @@
             raise BQApiError("need at least one selector to find output")
         self.wait()
         extra_patterns = []
         extra_filters = []
         for idx, (key, val) in enumerate(selectors.items()):
             val = val.get_docid() if isinstance(val, VQResource) else str(val)
             extra_patterns.append(f"?inputs :// tag:?tag{idx}")
-            extra_filters.append(
-                f'?tag{idx}/@name = "{key}" AND ?tag{idx}/@value_str = "{val}"'
-            )
+            extra_filters.append(f'?tag{idx}/@name = "{key}" AND ?tag{idx}/@value_str = "{val}"')
         extra_patterns = ". ".join(extra_patterns)
         extra_filters = " AND ".join(extra_filters)
         query = f"""
             SELECT ?out/@resource_uniq AS out_docid
                    ?out/@node_id AS out_id
                    ?out/@type AS out_type
                    ?out/@value_str AS out_val
@@ -457,33 +445,29 @@
 
         Returns:
             List[Tuple[str,str,object]]: list of (input name, input type, default value)
         """
         self._refresh(lvls=sys.maxsize)
         return [
             (module_arg.get_attr("name"), _get_param_types(module_arg))
-            for module_arg in self._doc.path_query(
-                '/module/inputs//*[not(@type) or @type != "group"][./template]'
-            )
+            for module_arg in self._doc.path_query('/module/inputs//*[not(@type) or @type != "group"][./template]')
         ]
 
     @property
     def outputs(self) -> List[Tuple[str, str]]:
         """
         Get list of output names.
 
         Returns:
             List[Tuple[str,str]]: list of (output name, output type)
         """
         self._refresh(lvls=sys.maxsize)
         return [
             (module_arg.get_attr("name"), _get_param_types(module_arg, "doc"))
-            for module_arg in self._doc.path_query(
-                '/module/outputs//*[not(@type) or @type != "group"][./template]'
-            )
+            for module_arg in self._doc.path_query('/module/outputs//*[not(@type) or @type != "group"][./template]')
         ]
 
 
 class VQBuild(VQResource):
     resource_type = "build"
 
     @classmethod
@@ -511,17 +495,15 @@
                         ?bld/@name = "{version}" )
             }}
             """
         matches = run_sparql_query(sess, query)
         if len(matches) == 0:
             raise BQApiError(f'module "{module_name}" (version "{version}") not found')
         if len(matches) > 1:
-            raise BQApiError(
-                f'multiple modules "{module_name}" (version "{version}") found'
-            )
+            raise BQApiError(f'multiple modules "{module_name}" (version "{version}") found')
         return VQResource.load(sess, matches[0]["build_id"])
 
     def get_module(self) -> VQModule:
         """
         Get module def for this build.
 
         Returns:
@@ -538,33 +520,29 @@
 
         Returns:
             List[Tuple[str,str,object]]: list of (input name, input type, default value)
         """
         self._refresh(lvls=sys.maxsize)
         return [
             (module_arg.get_attr("name"), _get_param_types(module_arg))
-            for module_arg in self._doc.path_query(
-                '/build/inputs//*[not(@type) or @type != "group"][./template]'
-            )
+            for module_arg in self._doc.path_query('/build/inputs//*[not(@type) or @type != "group"][./template]')
         ]
 
     @property
     def outputs(self) -> List[Tuple[str, str]]:
         """
         Get list of output names.
 
         Returns:
             List[Tuple[str,str]]: list of (output name, output type)
         """
         self._refresh(lvls=sys.maxsize)
         return [
             (module_arg.get_attr("name"), _get_param_types(module_arg, "doc"))
-            for module_arg in self._doc.path_query(
-                '/build/outputs//*[not(@type) or @type != "group"][./template]'
-            )
+            for module_arg in self._doc.path_query('/build/outputs//*[not(@type) or @type != "group"][./template]')
         ]
 
     def start(
         self,
         _keep_log: bool = False,
         _extra_tags: dict = None,
         _execute_options: dict = None,
@@ -591,73 +569,58 @@
         self._refresh(lvls=sys.maxsize)  # we need most of the doc anyway
 
         # create new mex resource based on build doc
         mex_doc = Metadoc(tag="mex")
 
         # find out if there are iterable inputs
         iterable_nodes = self._doc.path_query("/build/execute_options/iterable")
-        iterables = {
-            iterable_node.get_value(): iterable_node.get("type", "string")
-            for iterable_node in iterable_nodes
-        }
+        iterables = {iterable_node.get_value(): iterable_node.get("type", "string") for iterable_node in iterable_nodes}
 
         # copy inputs from build doc, remove templates and overwrite any params
         build_inputs = self._doc.path_query("/build/inputs")[0]
         mex_inputs = copy.deepcopy(build_inputs)
 
         # fill in parameters from kwargs
         add_iterables = {}
         for param_name, param_val in kwargs.items():
-            module_arg = mex_inputs.path_query(
-                f'/inputs//{param_name}[not(@type) or @type != "group"][./template]'
-            )
+            module_arg = mex_inputs.path_query(f'/inputs//{param_name}[not(@type) or @type != "group"][./template]')
             if len(module_arg) == 0:
                 raise BQApiError(f'Unknown module parameter "{param_name}"')
             module_arg = module_arg[0]
             single_param_val = param_val
             skip_typecheck = False
-            if isinstance(param_val, VQDataset) \
-               and param_name in iterables \
-               and iterables[param_name] == "dataset":
+            if isinstance(param_val, VQDataset) and param_name in iterables and iterables[param_name] == "dataset":
                 add_iterables[param_name] = "dataset"
-                skip_typecheck = (
-                    True  # would need to check the type of elements of dataset
-                )
+                skip_typecheck = True  # would need to check the type of elements of dataset
             elif isinstance(param_val, list) and not any(
                 ptype.startswith("list") for ptype in _get_param_types(module_arg)
             ):
                 if param_name in iterables and iterables[param_name] == "list":
                     add_iterables[param_name] = "list"
                     single_param_val = param_val[0]
                     param_val = ",".join(param_val)
                 else:
-                    raise BQApiError(
-                        f'List of values provided for non-iterable parameter "{param_name}"'
-                    )
+                    raise BQApiError(f'List of values provided for non-iterable parameter "{param_name}"')
             if not skip_typecheck:
                 if (
-                    isinstance(single_param_val, bool) \
-                    and "boolean" not in _get_param_types(module_arg)
-                ) or (
-                    isinstance(single_param_val, (int, float, complex)) \
-                    and "number" not in _get_param_types(module_arg)
-                ) or (
-                    isinstance(single_param_val, str) \
-                    and "string" not in _get_param_types(module_arg)
-                ) or (
-                    isinstance(single_param_val, list) \
-                    and not any(
-                        ptype.startswith("list")
-                        for ptype in _get_param_types(module_arg)
+                    (isinstance(single_param_val, bool) and "boolean" not in _get_param_types(module_arg))
+                    or (
+                        isinstance(single_param_val, (int, float, complex))
+                        and "number" not in _get_param_types(module_arg)
+                    )
+                    or (isinstance(single_param_val, str) and "string" not in _get_param_types(module_arg))
+                    or (
+                        isinstance(single_param_val, list)
+                        and not any(ptype.startswith("list") for ptype in _get_param_types(module_arg))
+                    )
+                    or (
+                        isinstance(single_param_val, VQResource)
+                        and single_param_val.resource_type not in _get_param_types(module_arg)
+                        and "resource" not in _get_param_types(module_arg)
                     )
-                ) or (
-                    isinstance(single_param_val, VQResource) \
-                    and single_param_val.resource_type \
-                    not in _get_param_types(module_arg) \
-                    and "resource" not in _get_param_types(module_arg)
                 ):
                     raise BQApiError(
                         f'Type mismatch for module parameter "{param_name}"; expected: {_get_param_types(module_arg)} got: {type(single_param_val)}'
                     )
             if isinstance(param_val, VQResource):
                 module_arg.set_value(param_val.get_docid())
                 module_arg.set_attr("type", param_val.resource_type)
@@ -695,17 +658,15 @@
             extra_tag = mex_doc.add_tag("optional-tags")
             for key, val in _extra_tags.items():
                 extra_tag.add_tag(key, value=val)
 
         # POST mex doc to mex_service to start module
         mex_service = self._sess.service("mexes")
         try:
-            mex_doc = mex_service.request(
-                path="/", method="post", render="doc", data=mex_doc
-            )
+            mex_doc = mex_service.request(path="/", method="post", render="doc", data=mex_doc)
             if not isinstance(mex_doc, Metadoc):
                 raise BQApiError(f"module could not be started: {mex_doc.text}")
         except Exception as exc:
             raise BQApiError(f"module could not be started: {str(exc)}")
 
         # return created mex resource
         return VQMex.load(self._sess, mex_doc.get_docid())
@@ -718,21 +679,19 @@
     def concat(
         sess: "VQSession",
         table_containers: List["VQTableContainer"],
         in_path: str,
         out_path: str,
         dim: int,
     ) -> "VQTableContainer":
-        pass  #!!!
+        pass  # !!!
 
     def get_array(self, path, slices=None):
         table_service = self._sess.service("tables")
-        return table_service.load_array(
-            table_uniq=self.get_docid(), path=path, slices=slices
-        )
+        return table_service.load_array(table_uniq=self.get_docid(), path=path, slices=slices)
 
     def get_table(self, path, slices=None, as_dataframe=True):
         table_service = self._sess.service("tables")
         return table_service.load_table(
             table_uniq=self.get_docid(),
             path=path,
             slices=slices,
@@ -818,19 +777,15 @@
                 geom.append(tn[0].get("value"))
             self._geometry = tuple(map(int, geom))
         return self._geometry
 
     def histogram(self):
         "returns image histogram"
         if self._histogram is None:
-            s = (
-                self.pixels()
-                .command("histogram", arguments="json")
-                .fetch(want_str=True)
-            )
+            s = self.pixels().command("histogram", arguments="json").fetch(want_str=True)
             h = json.loads(s)
             if "histogram" in h:
                 self._histogram = h["histogram"]
         return self._histogram
 
     def pixels(self):
         return self._sess.service("pixels").pixels(self.get_docid())
@@ -851,17 +806,15 @@
             session (BQSession): initialized session
             uniq (str): resource uniq
 
         Returns:
             VQResource: the resource object
         """
         meta = session.service("meta")
-        res = meta.request(
-            method="get", path="/" + uniq, params={}, view="short", render=None
-        )
+        res = meta.request(method="get", path="/" + uniq, params={}, view="short", render=None)
         if res.status_code != 200:
             raise BQApiError(f"resource {uniq} could not be loaded")
         doc_version = get_header(res, "ETag")
         doc = res.doc()
         resource_type = doc.tag
         attrs = {"value": doc.get_value()}
         for attr in doc.attrib:
@@ -894,17 +847,15 @@
         self,
         bisque_url,
         credentials=None,
         moduleuri=None,
         create_mex=False,
         enable_cache=True,
     ):
-        res = super().init(
-            bisque_url, credentials, moduleuri, create_mex, enable_cache=enable_cache
-        )
+        res = super().init(bisque_url, credentials, moduleuri, create_mex, enable_cache=enable_cache)
         self.factory = VQFactory()
         self._init_cache()
         return res
 
     def init_local(
         self,
         user,
@@ -925,17 +876,15 @@
             enable_cache=enable_cache,
         )
         self.factory = VQFactory()
         self._init_cache()
         return res
 
     def init_mex(self, mex_url, token, user=None, bisque_root=None, enable_cache=False):
-        res = super().init_mex(
-            mex_url, token, user, bisque_root, enable_cache=enable_cache
-        )
+        res = super().init_mex(mex_url, token, user, bisque_root, enable_cache=enable_cache)
         self.factory = VQFactory()
         self._init_cache()
         return res
 
     def init_request(self, request, enable_cache=True):
         res = super().init_request(request, enable_cache=enable_cache)
         self.factory = VQFactory()
```

## vqapi/vqquery.py

```diff
@@ -4,15 +4,15 @@
 from typing import List
 
 from vqapi.exception import BQApiError
 
 log = logging.getLogger("vqapi.vqquery")
 
 
-def run_sparql_query(sess: "VQSession", query: str, **kwargs) -> List:   # noqa
+def run_sparql_query(sess: "VQSession", query: str, **kwargs) -> List:  # noqa
     meta = sess.service("meta")
     matches = meta.request(
         method="get",
         path="/",
         params={"sparql_query": " ".join(query.split()), **kwargs},
         render="doc",
     ).to_json()["result"]
@@ -22,16 +22,16 @@
             matches = [matches]
     except KeyError:
         matches = []
     return matches
 
 
 def get_provenance(
-    sess: "VQSession", # noqa
-    seed: "VQResource", # noqa
+    sess: "VQSession",  # noqa
+    seed: "VQResource",  # noqa
     upstream: bool = True,
     downstream: bool = True,
     max_fanout: int = 3,
     out_format: str = "dot",
 ) -> object:
     """
     Experimental fct to retrieve provenance graph in DOT notation
@@ -80,17 +80,15 @@
                 type="mex",
                 supermex=True,
             )
             _cache_submexes(super_res)
         else:
             # this is a supermex or a normal mex => get/cache submexes and return res
             has_submexes = _cache_submexes(res)
-            super_res = Node(
-                id=res.id, name=res.name, type=res.type, supermex=has_submexes
-            )
+            super_res = Node(id=res.id, name=res.name, type=res.type, supermex=has_submexes)
         return super_res
 
     @lru_cache(maxsize=None)
     def _input_resources(res: Node) -> List[Node]:
         # return all input resources of mex
         # if res is supermex, look in all sub-mexes, otherwise look in res
         query = f"""
@@ -101,17 +99,15 @@
                 FILTER( ?submex/@resource_uniq = "{res.id}" AND
                         ?inputs/@name = "inputs" )
             }}
             """
         matches = run_sparql_query(sess, query)
         inputs = []
         for match in matches:
-            if match["in_val"] and (match["in_type"] or "string") in list(
-                sess.factory.resources.keys()
-            ) + ["resource"]:
+            if match["in_val"] and (match["in_type"] or "string") in list(sess.factory.resources.keys()) + ["resource"]:
                 vqr = sess.load(match["in_val"])
                 inputs.append(
                     Node(
                         id=vqr.get_docid(),
                         name=vqr.get("name"),
                         type=vqr.resource_type,
                         supermex=False,
@@ -131,17 +127,15 @@
                 FILTER( ?submex/@resource_uniq = "{res.id}" AND
                         ?outputs/@name = "outputs" )
             }}
             """
         matches = run_sparql_query(sess, query)
         outputs = []
         for match in matches:
-            if match["out_val"] and (match["out_type"] or "doc") in list(
-                sess.factory.resources.keys()
-            ) + ["resource"]:
+            if match["out_val"] and (match["out_type"] or "doc") in list(sess.factory.resources.keys()) + ["resource"]:
                 vqr = sess.load(match["out_val"])
                 outputs.append(
                     Node(
                         id=vqr.get_docid(),
                         name=vqr.get("name"),
                         type=vqr.resource_type,
                         supermex=False,
@@ -162,17 +156,15 @@
                         NOT EXISTSP {{ /mex:?supermex :/ mex:?submexref. ?submexref :-> ?mex }} )
             }}
             """
         matches = run_sparql_query(sess, query, limit=max_fanout + 1)
         mexes = []
         for idx, match in enumerate(matches):
             if idx == max_fanout:
-                mexes.append(
-                    Node(id=f"99-{more_cnt}", name=None, type=None, supermex=False)
-                )
+                mexes.append(Node(id=f"99-{more_cnt}", name=None, type=None, supermex=False))
                 more_cnt += 1
                 break
             vqr = sess.load(match["mex_id"])
             mexes.append(
                 Node(
                     id=vqr.get_docid(),
                     name=vqr.get("name"),
@@ -195,17 +187,15 @@
                         NOT EXISTSP {{ /mex:?supermex :/ mex:?submexref. ?submexref :-> ?mex }} )
             }}
             """
         matches = run_sparql_query(sess, query, limit=max_fanout + 1)
         mexes = []
         for idx, match in enumerate(matches):
             if idx == max_fanout:
-                mexes.append(
-                    Node(id=f"99-{more_cnt}", name=None, type=None, supermex=False)
-                )
+                mexes.append(Node(id=f"99-{more_cnt}", name=None, type=None, supermex=False))
                 more_cnt += 1
                 break
             vqr = sess.load(match["mex_id"])
             mexes.append(
                 Node(
                     id=vqr.get_docid(),
                     name=vqr.get("name"),
@@ -293,18 +283,15 @@
                 extras.append("color=red")
             if extras:
                 return "[" + ",".join(extras) + "]"
             else:
                 return ""
 
         dot_nodes = [f"{_dot_name(res)} {_dot_extras(res)}" for res in nodes.values()]
-        dot_edges = [
-            f"{_dot_name(nodes[res.from_id])} -> {_dot_name(nodes[res.to_id])}"
-            for res in edges
-        ]
+        dot_edges = [f"{_dot_name(nodes[res.from_id])} -> {_dot_name(nodes[res.to_id])}" for res in edges]
         return f"digraph {{ rankdir=LR; node [shape=box, margin=0.05, width=0, height=0, fontsize=10]; {'; '.join(dot_nodes)}; {'; '.join(dot_edges)} }}"
 
     elif out_format == "list":
         return [sess.load(res.id) for res in nodes.values()]
 
     else:
         raise BQApiError(f'unknown provenance format "{out_format}"')
```

## vqapi/RequestsMonkeyPatch/requests_patch.py

```diff
@@ -59,11 +59,9 @@
             else:
                 return result
 
         value_encode = str(value)
         # if not six.PY3: # Python 2:
         #    value_encode = value.encode('utf-8')
 
-        value = '{}="{}"; {}*={}'.format(
-            name, value, name, email.utils.encode_rfc2231(value_encode, "utf-8")
-        )
+        value = '{}="{}"; {}*={}'.format(name, value, name, email.utils.encode_rfc2231(value_encode, "utf-8"))
         return value
```

## Comparing `viqi_api-0.6.4.0.dist-info/RECORD` & `viqi_api-0.6.4.1.dist-info/RECORD`

 * *Files 22% similar despite different names*

```diff
@@ -1,33 +1,21 @@
 vqapi/README.md,sha256=7DM5QUu1mXfOR14RhMMZs1pJcr5GeWoCl68zOkryzZs,417
-vqapi/__init__.py,sha256=GIBfM2yry1veygFPtPuWtQJqrI6liIEe57eGU_Tc-SI,272
-vqapi/blockable_module.py,sha256=4T0S9unISZhBhi56_vXusI9phH99UZTW6Q7Vf9dAi6c,1743
-vqapi/bqclass.py,sha256=XbbQn8K2DkkDF2WDgarUyFelqUO0hZFaIJmQhx8SJJ0,28849
-vqapi/bqfeature.py.old,sha256=aZTD2vvvTffWVLEkVSFWmXZxEctre079bWCU8namrjk,16175
-vqapi/bqnode.py.save,sha256=ljeodGBMxDG0GtVjNEiMoXVtVabJXMjSQ0IrNlgPOEc,24743
-vqapi/casauth.py,sha256=DJcASWswnGUAkT-UMb0IvEpJajtmJtQ1Sl3j1WKeWeA,1594
-vqapi/cmd.py,sha256=02OR6lTbONqNmyjJ3puMsoSRJSeZIIoVCrf71SdzFwM,6312
-vqapi/comm.py,sha256=JAkukycUsMe09la8_C3_PLKxhYiYPCg9UX-PXno4mHo,50428
-vqapi/exception.py,sha256=t0CGgD5n_QifTPY4bO7ykJtAjyf_4D4ZFA5hdJBgfC4,14596
-vqapi/services.py,sha256=37Zq5IHdBQnGsPNGIOFQgBdvJLeF3myi2HMLsNjQkWo,60270
-vqapi/types.py,sha256=NM7TZH33_2dQpjUr6qt_o3eM2ph4jcOUlKLoEuZpF2w,79
-vqapi/util.py,sha256=pLB8u9rjOGR-s56QiA_QCNZSfDIz47NxgmjC_lCcf0Q,13956
-vqapi/version.py,sha256=iKeEU0kiJwrnPu9QkIQXAaD6GtuvxBxHHXvulMPUZPg,165
-vqapi/vqclass.py,sha256=1yzQmUGTjFbcHWHGK5KURd-JOb2opO6qdxQ00S_Dg_w,34260
-vqapi/vqquery.py,sha256=giltR26Bfanp9iyZ8WbmJwHuBT76QOyLv8qPbXhvk1Q,11536
+vqapi/__init__.py,sha256=TPscdodYorQvuwk8liRjU3TWM_GRl7c-kX59I6yqqn4,251
+vqapi/blockable_module.py,sha256=zMeKq_h2TZLGAvnvuJbf9K0LdzWHNjs_iRdRaB81f8M,1746
+vqapi/bqclass.py,sha256=wJWMdfULDka_6ts2QMFolcsTmXEcYT6F66Ssd7Zf9bQ,28745
+vqapi/casauth.py,sha256=dCmb2VzoyEeo2OL6ffbEutrsmen_ES5hN896TGd5WMw,1595
+vqapi/cmd.py,sha256=YJBN0GkqC9pTPKM_HR-zG8tkAHfwUvQP4ahB7Tau69w,6106
+vqapi/comm.py,sha256=bL70akb44eMsti-PrK92DFR8TCHiI2oge0V2E4EgjfU,50118
+vqapi/exception.py,sha256=3gBTtX8YBJwEpTZC-xIh0P1GAcFvRFZmw7aZigcAOe4,14598
+vqapi/services.py,sha256=HRs5hIzrqv1xDGiBHRaJY4EBFZLn9g1-Z8ch-Usgy_M,61279
+vqapi/util.py,sha256=5veo8qvyT0DXj_pGg6Kq9kHQ_tGUNej_Ze5wj_l1YCA,13926
+vqapi/version.py,sha256=aSsrluLS7iUm-AsEfNtcxQSx1hUsntdxtV3UPyT97Tg,165
+vqapi/vqclass.py,sha256=AhA9d1liWCn69TOD-ddtPtA55Q0GEzNnTNnhZigqImo,33507
+vqapi/vqquery.py,sha256=eCj5EuzGmudAMT0yam9LsD_sJ76niSMWSsYc53ttZJc,11337
 vqapi/xmldict.py,sha256=LlALxsgBZS0Put8rRj6T4S5xMoI1h5gfZvk_bSKivec,4604
 vqapi/RequestsMonkeyPatch/__init__.py,sha256=9_8wL9Scv8_Cs8HJyJHGvx1vwXErsuvlsAqNZLcJQR0,8
 vqapi/RequestsMonkeyPatch/monkeypatch.py,sha256=Dl9WR-wicHkgxKRWZ4yXvs4RMuu9v3CSY3fBMlH3Fl0,138
-vqapi/RequestsMonkeyPatch/requests_patch.py,sha256=sw_TrcJ8fc3YHr84jr7V2y-12A7SloEv5fUrca8QDI4,2032
-vqapi/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-vqapi/tests/conftest.py,sha256=BAKLh1rNX9dhEnCk82qMkstCrYpKKnAxjLc0MubuVqw,800
-vqapi/tests/setup.cfg.sample,sha256=GBXsPcmUXtYFTLleRqLRmb0FXU4VEE0AZA5hCk9-x-4,254
-vqapi/tests/test_bqapi.py,sha256=YbVateKKeqnjL6FxoFN3JLBHs4VewClqZp_13gOjuHY,848
-vqapi/tests/test_bqclass.py,sha256=4Fvy3cmp_-7yROI4Xfu-h0eqZPfoa4bP0wO69V4RMXs,516
-vqapi/tests/test_bqfeature.py,sha256=ZLTQu-flD-RlZe3GHAy2XSUFLacpplG5BeQ9Q6Clhm0,6626
-vqapi/tests/test_comm.py,sha256=fF2zF0Mqfi_64oX1eO_xsxBP3Hg0oFKUbv600uAyGu0,6645
-vqapi/tests/test_util.py,sha256=j6Q1KfiWe93dts5pUxmZ1KkJtkEXAjl2jCS5-h6wm8g,8071
-vqapi/tests/util.py,sha256=mR9H6drhnmsMCI8v26uiF7_aO9E3vx-5P-F2tBCSMo8,575
-viqi_api-0.6.4.0.dist-info/METADATA,sha256=wLBmsSH4k1lPin6qCjSdIdSoODu7DdGyiIbcMCgDReY,905
-viqi_api-0.6.4.0.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
-viqi_api-0.6.4.0.dist-info/top_level.txt,sha256=3tj8lcUB1FkjX_EiiFuj3I18i3_LJydRRS0stEFKdJU,6
-viqi_api-0.6.4.0.dist-info/RECORD,,
+vqapi/RequestsMonkeyPatch/requests_patch.py,sha256=CsXlC4OtK1tBVE4I1_ZU75RHGSQgTuSJREqcsM4yjgs,2010
+viqi_api-0.6.4.1.dist-info/METADATA,sha256=jE0wvADmU3htKZ_LSF3EPU9JgcWqfRfm_L4ZG8o5yDM,1509
+viqi_api-0.6.4.1.dist-info/WHEEL,sha256=pkctZYzUS4AYVn6dJ-7367OJZivF2e8RA9b_ZBjif18,92
+viqi_api-0.6.4.1.dist-info/top_level.txt,sha256=3tj8lcUB1FkjX_EiiFuj3I18i3_LJydRRS0stEFKdJU,6
+viqi_api-0.6.4.1.dist-info/RECORD,,
```

